{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monet Cycle-GAN Project\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Author: Kevin Paganini    \n",
    "Date: 11/29/2022     \n",
    "Description: Using a cycle-GAN to transform images to art :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import glob as gb\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_rows', 250)\n",
    "\n",
    "\n",
    "# makes plots nice\n",
    "def make_pretty(ax, title='', x_label='', y_label='', img=False):\n",
    "    ax.set_title(title, fontsize=20)\n",
    "    ax.set_xlabel(x_label, fontsize=16)\n",
    "    ax.set_ylabel(y_label, fontsize=16)\n",
    "    ax.legend(loc='best', fontsize=16)\n",
    "    if img:\n",
    "        ax.axis('off')\n",
    "    return ax\n",
    "\n",
    "\n",
    "monet_jpg_path = os.path.join('data', 'monet_jpg')\n",
    "photo_jpg_path = os.path.join('data', 'photo_jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total monet jpg images: 300\n",
      "Total monet jpg images: 7038\n"
     ]
    }
   ],
   "source": [
    "total_monet_jpg = 0\n",
    "for d in os.listdir(monet_jpg_path):\n",
    "    total_monet_jpg += 1\n",
    "\n",
    "print(f'Total monet jpg images: {total_monet_jpg}')\n",
    "\n",
    "\n",
    "\n",
    "total_photo_jpg = 0\n",
    "for d in os.listdir(photo_jpg_path):\n",
    "    total_photo_jpg += 1\n",
    "\n",
    "print(f'Total monet jpg images: {total_photo_jpg}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying some monet pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and making sure we have regular shape images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of Cycle GANs\n",
    "\n",
    "The problem we are trying to tackle is an unpaired Image-to_image translation. Since it is impossible to have a dataset that includes pairs of images plus their monet counterparts we have come up with a clever way solve the problem. \n",
    "\n",
    "In this project we are doing an Image-to-Image translation task. At a high level we are training to 4 models. Two of them will be generators and two of them will be discriminators. In our case we will be making a generator that will take an input image X (a real image in our case) and produce an output image Y (a monet style painting of the input image). The discrimninator will try to discern whether the an image provided to it is a real monet or a fake produce by the generator. The second generator we will produce is a generator that as input will take an input image Y and produce the output image X. The discrimnator in this case will try to determine whether the an image provided to it is a real image or a fake produce by the generator.   \n",
    "\n",
    "This architecture alone could be enough to produce plausible images in the other domain, however it won't produce translations of the input images. This is why we need to use cycle consistency. The idea here is that the output of one generator model can be used as an input to the other generator model. The output of the second generator model should produce the original input image. We ensure this by introducing another factor to our loss function. We measure the difference between the final output image and the original input to enforce this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources and Links\n",
    "---------------------------------------------------------------\n",
    "\n",
    "https://hardikbansal.github.io/CycleGANBlog/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81f99e49c349529997f0144da639a0cd7f0aa4ec4a9596435a58ff9569a503c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
